{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e4a671e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Page 1 done\n",
      "\n",
      "üéâ Done! Saved 20 books to books.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "pages = int(input(\"How many pages to crawl: \"))  # User input\n",
    "data = []  # Store all book info\n",
    "\n",
    "for i in range(1, pages + 1):\n",
    "    url = f\"https://books.toscrape.com/catalogue/page-{i}.html\"  # Page URL\n",
    "    try:\n",
    "        r = requests.get(url, timeout=10)  # Fetch page\n",
    "    except:\n",
    "        print(f\"‚ö†Ô∏è Page {i} failed, skipping\")  # Handle network issues\n",
    "        continue\n",
    "\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")  # Parse HTML\n",
    "    for p in soup.select(\".product_pod\"):\n",
    "        title = p.h3.a[\"title\"].strip()  # Book title\n",
    "        raw_price = p.select_one(\".price_color\").text.strip()  # Raw price\n",
    "        price = raw_price.encode(\"latin1\").decode(\"utf-8\")  # Fix encoding (removes √Ç)\n",
    "        link = \"https://books.toscrape.com/catalogue/\" + p.h3.a[\"href\"]  # Full product link\n",
    "        data.append({\"Name\": title, \"Price\": price, \"Link\": link})  # Add data to list\n",
    "    print(f\"‚úÖ Page {i} done\")\n",
    "\n",
    "# ---- Save to CSV with headings ----\n",
    "with open(\"books.csv\", \"w\", newline=\"\", encoding=\"utf-8-sig\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=[\"Name\", \"Price\", \"Link\"])  # Define headers\n",
    "    writer.writeheader()  # ‚úÖ Add headings\n",
    "    writer.writerows(data)  # Write all rows\n",
    "\n",
    "print(f\"\\nüéâ Done! Saved {len(data)} books to books.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a3ac7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved 20 books\n"
     ]
    }
   ],
   "source": [
    "import requests, csv\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "pages = int(input(\"Pages: \"))\n",
    "data = []\n",
    "\n",
    "for i in range(1, pages + 1):\n",
    "    try:\n",
    "        html = requests.get(f\"https://books.toscrape.com/catalogue/page-{i}.html\", timeout=10).text\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    for p in soup.select(\".product_pod\"):\n",
    "        data.append({\n",
    "            \"Name\": p.h3.a[\"title\"],\n",
    "            \"Price\": p.select_one(\".price_color\").text.replace(\"√Ç\", \"\"),\n",
    "            \"Link\": \"https://books.toscrape.com/catalogue/\" + p.h3.a[\"href\"]\n",
    "        })\n",
    "\n",
    "with open(\"books1.csv\", \"w\", newline=\"\", encoding=\"utf-8-sig\") as f:\n",
    "    csv.DictWriter(f, [\"Name\", \"Price\", \"Link\"]).writerows(data)\n",
    "\n",
    "print(f\"‚úÖ Saved {len(data)} books\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
